{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make sure all libraries are installed and they work\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import doc2vec\n",
    "from sklearn import utils\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "import re\n",
    "import xgboost \n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import logging\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import nltk\n",
    "from sklearn import naive_bayes,svm, metrics,naive_bayes,ensemble\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,f1_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis,QuadraticDiscriminantAnalysis\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import utils\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function needed to label each document (part of the pre processing step for doc2vec)\n",
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the post.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(doc2vec.TaggedDocument(v.split(), [label]))\n",
    "    return labeled\n",
    "\n",
    "# adding C to the classess that dont have it \n",
    "def addClass(x):\n",
    "    firstWord = x[0]\n",
    "    if (firstWord!='C'):\n",
    "        x = \"C\" + str(x)\n",
    "    return str(x)\n",
    "\n",
    "#function to clean the data\n",
    "def clean_text(text):\n",
    "    REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "    BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "\n",
    "# function needed to label each document (part of the pre processing step for doc2vec)\n",
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the post.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(doc2vec.TaggedDocument(v.split(), [label]))\n",
    "    return labeled\n",
    "\n",
    "# function to get vector for the doc2vec model\n",
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors\n",
    "\n",
    "# coverting all elements of a list to string\n",
    "def arrayToString(x):\n",
    "    return [str(i) for i in x]\n",
    "\n",
    "def convertToString(x):\n",
    "    x = str(x)\n",
    "    return x\n",
    "\n",
    "# convert array to a string\n",
    "def splitString(x):\n",
    "    x1 = ' '.join(x)\n",
    "    return x1\n",
    "\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, valid_y, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return [metrics.accuracy_score(predictions, valid_y),predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "############################################################################################################\n",
    "############################################################################################################\n",
    "########################################## PRE PROCESS TEST DATA ###########################################\n",
    "############################################################################################################\n",
    "############################################################################################################\n",
    "############################################################################################################\n",
    "############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26610\n",
      "26610\n"
     ]
    }
   ],
   "source": [
    "#pre process and extraction of data\n",
    "file = \"./testing_docs.txt\"\n",
    "with open(file,'r',encoding=\"utf8\") as theFile:\n",
    "\n",
    "    text = theFile.readlines()\n",
    "text[0:5]\n",
    "textList = []\n",
    "i=0\n",
    "j=len(text)\n",
    "while i<j:\n",
    "    textList.append(text[i:i+2])\n",
    "    i+=4\n",
    "print(len(textList))\n",
    "i=0\n",
    "j=len(textList)\n",
    "while i<j:\n",
    "    textList[i][0]=textList[i][0][3:-1]\n",
    "    textList[i][1]=textList[i][1][5:-1]\n",
    "    i+=1\n",
    "#textList[0:2]\n",
    "print(len(textList))\n",
    "\n",
    "# creating data frame, one column for doc and one for the text in it\n",
    "cols = ['ID','TEXT']\n",
    "assignTestSet = pd.DataFrame(textList[0:],columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignTestSet['TEXT'] = assignTestSet['TEXT'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>te_doc_1</td>\n",
       "      <td>police royal commission western australia hear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>te_doc_2</td>\n",
       "      <td>northern territory government says queensland ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>te_doc_3</td>\n",
       "      <td>group hepatitis c sufferers infected blood tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>te_doc_4</td>\n",
       "      <td>crew north korean vessel pong su appear sydney...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>te_doc_5</td>\n",
       "      <td>new south wales supreme court told magistrate ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               TEXT\n",
       "0  te_doc_1  police royal commission western australia hear...\n",
       "1  te_doc_2  northern territory government says queensland ...\n",
       "2  te_doc_3  group hepatitis c sufferers infected blood tra...\n",
       "3  te_doc_4  crew north korean vessel pong su appear sydney...\n",
       "4  te_doc_5  new south wales supreme court told magistrate ..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(assignTestSet)\n",
    "assignTestSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26610"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(assignTestSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "############################################################################################################\n",
    "############################################################################################################\n",
    "######################################### PRE PROCESS TRAIN DATA ###########################################\n",
    "############################################################################################################\n",
    "############################################################################################################\n",
    "############################################################################################################\n",
    "############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106445\n",
      "106445\n"
     ]
    }
   ],
   "source": [
    "#pre process and extraction of data\n",
    "file = \"./training_docs.txt\"\n",
    "with open(file,'r',encoding=\"utf8\") as theFile:\n",
    "\n",
    "    text = theFile.readlines()\n",
    "text[0:5]\n",
    "textList = []\n",
    "i=0\n",
    "j=len(text)\n",
    "while i<j:\n",
    "    textList.append(text[i:i+2])\n",
    "    i+=4\n",
    "print(len(textList))\n",
    "i=0\n",
    "j=len(textList)\n",
    "while i<j:\n",
    "    textList[i][0]=textList[i][0][3:-1]\n",
    "    textList[i][1]=textList[i][1][5:-1]\n",
    "    i+=1\n",
    "#textList[0:2]\n",
    "print(len(textList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data frame, one column for doc and one for the text in it\n",
    "cols = ['ID','TEXT']\n",
    "trDocs = pd.DataFrame(textList[0:],columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre processing label\n",
    "file = \"./training_labels_final.txt\"\n",
    "with open(file,'r',encoding=\"utf8\") as theFile:\n",
    "    text = theFile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating out the labels \n",
    "theLabel = []\n",
    "i=0\n",
    "while i < len(text):\n",
    "    theLabel.append(text[i][-3:-1])\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding labels to the dataframe\n",
    "theLabel = pd.Series(theLabel)\n",
    "trDocs['doc.class'] = theLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>doc.class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr_doc_1</td>\n",
       "      <td>Two German tourists have been found safe and w...</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr_doc_2</td>\n",
       "      <td>ACT police have seized a rare drug during a ra...</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tr_doc_3</td>\n",
       "      <td>A 50-year-old Brisbane man has been charged wi...</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tr_doc_4</td>\n",
       "      <td>In-depth discussions are continuing to resolve...</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tr_doc_5</td>\n",
       "      <td>Homicide detectives are still questioning a ma...</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               TEXT doc.class\n",
       "0  tr_doc_1  Two German tourists have been found safe and w...        C1\n",
       "1  tr_doc_2  ACT police have seized a rare drug during a ra...        C1\n",
       "2  tr_doc_3  A 50-year-old Brisbane man has been charged wi...        C1\n",
       "3  tr_doc_4  In-depth discussions are continuing to resolve...        C1\n",
       "4  tr_doc_5  Homicide detectives are still questioning a ma...        C1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data frame ready\n",
    "trDocs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11',\n",
       "       'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20',\n",
       "       'C21', 'C22', 'C23'], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trDocs['doc.class'] = trDocs['doc.class'].apply(addClass)\n",
    "# trDocs['doc.class'] = trDocs['doc.class'].convertToString(addClass)\n",
    "trDocs['doc.class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2174)\n",
    "trDocs = trDocs.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>doc.class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr_doc_51653</td>\n",
       "      <td>Serena Williams, who underwent knee surgery in...</td>\n",
       "      <td>C12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr_doc_62093</td>\n",
       "      <td>The State Member for Barwon, Ian Slack-Smith, ...</td>\n",
       "      <td>C14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tr_doc_103628</td>\n",
       "      <td>Eleven miners have been killed and another 25 ...</td>\n",
       "      <td>C23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tr_doc_51774</td>\n",
       "      <td>World number 15 Jelena Dokic has withdrawn fro...</td>\n",
       "      <td>C12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tr_doc_49593</td>\n",
       "      <td>Melbourne Victory captain Kevin Muscat has lab...</td>\n",
       "      <td>C11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                               TEXT doc.class\n",
       "0   tr_doc_51653  Serena Williams, who underwent knee surgery in...       C12\n",
       "1   tr_doc_62093  The State Member for Barwon, Ian Slack-Smith, ...       C14\n",
       "2  tr_doc_103628  Eleven miners have been killed and another 25 ...       C23\n",
       "3   tr_doc_51774  World number 15 Jelena Dokic has withdrawn fro...       C12\n",
       "4   tr_doc_49593  Melbourne Victory captain Kevin Muscat has lab...       C11"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trDocs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "trDocs['TEXT'] = trDocs['TEXT'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4102, 102089, 6525, 87597, 11603]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thelist = np.arange(1,106445)\n",
    "removeRows = np.random.choice(thelist,5).tolist()\n",
    "removeRows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "trDocs1 = trDocs.drop(removeRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>doc.class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr_doc_51653</td>\n",
       "      <td>serena williams underwent knee surgery august ...</td>\n",
       "      <td>C12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr_doc_62093</td>\n",
       "      <td>state member barwon ian slacksmith called redu...</td>\n",
       "      <td>C14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tr_doc_103628</td>\n",
       "      <td>eleven miners killed another 25 trapped two se...</td>\n",
       "      <td>C23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tr_doc_51774</td>\n",
       "      <td>world number 15 jelena dokic withdrawn next we...</td>\n",
       "      <td>C12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tr_doc_49593</td>\n",
       "      <td>melbourne victory captain kevin muscat labelle...</td>\n",
       "      <td>C11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                               TEXT doc.class\n",
       "0   tr_doc_51653  serena williams underwent knee surgery august ...       C12\n",
       "1   tr_doc_62093  state member barwon ian slacksmith called redu...       C14\n",
       "2  tr_doc_103628  eleven miners killed another 25 trapped two se...       C23\n",
       "3   tr_doc_51774  world number 15 jelena dokic withdrawn next we...       C12\n",
       "4   tr_doc_49593  melbourne victory captain kevin muscat labelle...       C11"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trDocs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of trDocs 106440\n"
     ]
    }
   ],
   "source": [
    "trDocs1.head()\n",
    "print('length of trDocs',len(trDocs1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>te_doc_1</td>\n",
       "      <td>police royal commission western australia hear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>te_doc_2</td>\n",
       "      <td>northern territory government says queensland ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>te_doc_3</td>\n",
       "      <td>group hepatitis c sufferers infected blood tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>te_doc_4</td>\n",
       "      <td>crew north korean vessel pong su appear sydney...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>te_doc_5</td>\n",
       "      <td>new south wales supreme court told magistrate ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               TEXT\n",
       "0  te_doc_1  police royal commission western australia hear...\n",
       "1  te_doc_2  northern territory government says queensland ...\n",
       "2  te_doc_3  group hepatitis c sufferers infected blood tra...\n",
       "3  te_doc_4  crew north korean vessel pong su appear sydney...\n",
       "4  te_doc_5  new south wales supreme court told magistrate ..."
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignTestSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = trDocs1.append(assignTestSet)\n",
    "dfx = dfx.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133050"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>doc.class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133045</th>\n",
       "      <td>26605</td>\n",
       "      <td>te_doc_26606</td>\n",
       "      <td>new report warns average temperatures rise 6 d...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133046</th>\n",
       "      <td>26606</td>\n",
       "      <td>te_doc_26607</td>\n",
       "      <td>international report shown students smaller we...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133047</th>\n",
       "      <td>26607</td>\n",
       "      <td>te_doc_26608</td>\n",
       "      <td>chinese farmer invented survival pod hopes ado...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133048</th>\n",
       "      <td>26608</td>\n",
       "      <td>te_doc_26609</td>\n",
       "      <td>friday end mayan calendar people believe also ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133049</th>\n",
       "      <td>26609</td>\n",
       "      <td>te_doc_26610</td>\n",
       "      <td>scientists united states offered molecularleve...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index            ID  \\\n",
       "133045  26605  te_doc_26606   \n",
       "133046  26606  te_doc_26607   \n",
       "133047  26607  te_doc_26608   \n",
       "133048  26608  te_doc_26609   \n",
       "133049  26609  te_doc_26610   \n",
       "\n",
       "                                                     TEXT doc.class  \n",
       "133045  new report warns average temperatures rise 6 d...       NaN  \n",
       "133046  international report shown students smaller we...       NaN  \n",
       "133047  chinese farmer invented survival pod hopes ado...       NaN  \n",
       "133048  friday end mayan calendar people believe also ...       NaN  \n",
       "133049  scientists united states offered molecularleve...       NaN  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into test and train data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfx['TEXT'], dfx['doc.class'], test_size=0.2, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling each document part of preproces for doc2vec\n",
    "X_train = label_sentences(X_train, 'Train')\n",
    "X_test = label_sentences(X_test, 'Test')\n",
    "all_data = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133050"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133050/133050 [00:00<00:00, 1907524.95it/s]\n",
      "100%|██████████| 133050/133050 [00:00<00:00, 1439729.59it/s]\n",
      "100%|██████████| 133050/133050 [00:00<00:00, 1461336.20it/s]\n",
      "100%|██████████| 133050/133050 [00:00<00:00, 2329886.76it/s]\n",
      "100%|██████████| 133050/133050 [00:00<00:00, 2016179.04it/s]\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "# running model doc2vec\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=500, negative=5, min_count=1, alpha=0.065, min_alpha=0.045)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])\n",
    "\n",
    "# need to change the range to train model better\n",
    "# someone try it with 100\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha\n",
    "print(datetime.datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try getting more vectors, instead of 300 try 500 or 1000\n",
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 500, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 500, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_vectors_dbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying LDA using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "scores = cross_val_score(clf, train_vectors_dbow, y_train, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.datetime.now() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying SVM (radial kernal) using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "clf1 = SVC(gamma='auto',kernel='radial')\n",
    "scores1 = cross_val_score(clf1, train_vectors_dbow, y_train, cv=5)\n",
    "scores1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.datetime.now() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying logistic regression using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "start = datetime.datetime.now()\n",
    "logreg.fit(train_vectors_dbow, y_train)\n",
    "y_pred = logreg.predict(test_vectors_dbow)\n",
    "datetime.datetime.now() - start \n",
    "print('Testing accuracy LR %s' % accuracy_score(y_test, y_pred))\n",
    "print(datetime.datetime.now() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying LDA using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying lda\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(train_vectors_dbow, y_train)\n",
    "x = clf.predict(test_vectors_dbow)\n",
    "print('Testing accuracy lda %s' % accuracy_score(y_test, x))\n",
    "f1_score(y_test, x,average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying QDA using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying qda\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(train_vectors_dbow, y_train)\n",
    "x1 = qda.predict(test_vectors_dbow)\n",
    "print('Testing accuracy qda %s' % accuracy_score(y_test, x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying random forest using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), train_vectors_dbow, y_train,test_vectors_dbow, y_test)\n",
    "print (\"Radom forest, doc2Vec: \", accuracy)\n",
    "print(datetime.datetime.now() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying SVM (sigmoid kernal) using cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model SVM\n",
    "start = datetime.datetime.now()\n",
    "from sklearn.svm import SVC\n",
    "claffifier1 = SVC(gamma='auto',kernel='sigmoid')\n",
    "claffifier1.fit(train_vectors_dbow, y_train)\n",
    "theFinalResult = claffifier1.predict(test_vectors_dbow)\n",
    "print(datetime.datetime.now() - start)\n",
    "print('Accuracy SVM',accuracy_score(theFinalResult, y_test)\n",
    "print('F Score SVM',f1_score(y_test, theFinalResult,average='weighted'))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
